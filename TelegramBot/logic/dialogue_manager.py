
import logging
from typing import Dict, Any, Optional
from copy import deepcopy

from utils.context_manager import RedisContextManager

logger = logging.getLogger(__name__)

class DialogueManager:
    def __init__(self, context_manager: RedisContextManager):
        self.context_manager = context_manager

    def _filter_blocked_responses(self, response: list) -> list:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –±–æ—Ç–∞ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é"""
        blocked_phrases = [
            "—è –Ω–µ –≥–æ—Ç–æ–≤ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å",
            "—è –Ω–µ –≥–æ—Ç–æ–≤ –ø—Ä–æ —ç—Ç–æ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å", 
            "—è –Ω–µ –º–æ–≥—É —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å",
            "—è –Ω–µ —É–º–µ—é —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å",
            "–∏–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –ø–æ–Ω–∏–º–∞—é"
        ]
        
        filtered_response = []
        for resp in response:
            if resp.get("type") == "text":
                content = resp.get("content", "").lower()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
                if not any(phrase in content for phrase in blocked_phrases):
                    filtered_response.append(resp)
                else:
                    logger.info(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç: {resp.get('content')}")
            else:
                # –ù–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã (–∫–∞—Ä—Ç—ã, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                filtered_response.append(resp)
        
        return filtered_response

    async def enrich_request(
        self, user_id: str, current_analysis: Dict[str, Any], current_query: str
    ) -> Dict[str, Any]:
        
        # --- [–ù–û–í–û–ï] –®–∞–≥ 1: –§–∏–ª—å—Ç—Ä "–ø—É—Å—Ç—ã—Ö" –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ ---
        is_chitchat = (
            current_analysis.get("action") == "unknown" and 
            not (current_analysis.get("primary_entity") and current_analysis.get("primary_entity").get("name")) and
            not (current_analysis.get("secondary_entity") and current_analysis.get("secondary_entity").get("name")) and
            not current_analysis.get("attributes")
        )
        if is_chitchat:
            logger.info(f"[{user_id}] –ó–∞–ø—Ä–æ—Å '{current_query}' —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω –∫–∞–∫ 'small talk' –î–û –æ–±–æ–≥–∞—â–µ–Ω–∏—è. –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è.")
            return current_analysis # –í–æ–∑–≤—Ä–∞—â–∞–µ–º "–ø—É—Å—Ç–æ–π" –∞–Ω–∞–ª–∏–∑ –∫–∞–∫ –µ—Å—Ç—å

        # --- [–û–°–¢–ê–õ–¨–ù–ê–Ø –õ–û–ì–ò–ö–ê, –ï–°–õ–ò –≠–¢–û –ù–ï "–ü–£–°–¢–û–ô" –ó–ê–ü–†–û–°] ---
        
        last_history_entry = await self.get_latest_history(user_id)
        if not last_history_entry:
            return current_analysis

        # –ï—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º –∑–∞–ø—Ä–æ—Å–µ –µ—Å—Ç—å –Ω–æ–≤—ã–π —è–≤–Ω—ã–π –æ–±—ä–µ–∫—Ç, —ç—Ç–æ —Å–º–µ–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ–±—ä–µ–∫—Ç–∞.
        if current_analysis.get("primary_entity") and current_analysis.get("primary_entity").get("name"):
            logger.debug(f"[{user_id}] –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å–º–µ–Ω–∞ –æ–±—ä–µ–∫—Ç–∞ –Ω–∞ '{current_analysis['primary_entity']['name']}'. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ.")
            final_analysis = current_analysis
            # –ï—Å–ª–∏ –≤ –Ω–æ–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ –Ω–µ –±—ã–ª–æ –¥–µ–π—Å—Ç–≤–∏—è, –Ω–∞—Å–ª–µ–¥—É–µ–º –µ–≥–æ –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ
            if final_analysis.get("action") == "unknown":
                final_analysis["action"] = last_history_entry.get("analysis", {}).get("action")
            
            logger.info(f"[{user_id}] –ò–¢–û–ì –û–ë–û–ì–ê–©–ï–ù–ò–Ø (—Å–º–µ–Ω–∞ –æ–±—ä–µ–∫—Ç–∞): {final_analysis}")
            return final_analysis

        # –ï—Å–ª–∏ –Ω–æ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ—Ç, —ç—Ç–æ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞.
        logger.debug(f"[{user_id}] –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.")
        
        final_analysis = deepcopy(last_history_entry.get("analysis", {}))
        
        last_used_objects = last_history_entry.get("used_objects", [])
        if last_used_objects:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤ used_objects –Ω–µ –≥–µ–æ-–æ–±—ä–µ–∫—Ç—ã (–≤–∞–∂–Ω–æ –¥–ª—è "–ê –≥–¥–µ –æ–Ω–∞ –æ–±–∏—Ç–∞–µ—Ç?")
            is_biological = last_used_objects[0].get("type") == "biological_entity"
            is_infrastructure = last_used_objects[0].get("type") == "infrastructure_entity" # –î–æ–±–∞–≤–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É

            if is_biological or is_infrastructure:
                context_object = last_used_objects[0]
                final_analysis["primary_entity"] = { "name": context_object.get("name"), "type": "Biological" if is_biological else "Infrastructure" }

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–¥–µ–π—Å—Ç–≤–∏–µ, –∞—Ç—Ä–∏–±—É—Ç—ã) –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        if current_analysis.get("action") != "unknown":
            final_analysis["action"] = current_analysis["action"]
        final_analysis.setdefault("attributes", {}).update(current_analysis.get("attributes", {}))
        if current_analysis.get("secondary_entity"):
            final_analysis["secondary_entity"] = current_analysis["secondary_entity"]
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è "–ü–æ–∫–∞–∂–∏ –∏—Ö –Ω–∞ –∫–∞—Ä—Ç–µ"
        plural_markers = ["–∏—Ö", "—ç—Ç–∏", "–≤—Å–µ—Ö"]
        is_plural_query = any(marker in current_query.lower() for marker in plural_markers)
        if final_analysis.get("action") == "show_map" and is_plural_query and last_used_objects and len(last_used_objects) > 1:
            final_analysis["used_objects_from_context"] = last_used_objects
            final_analysis["primary_entity"] = None

        logger.info(f"[{user_id}] –ò–¢–û–ì –û–ë–û–ì–ê–©–ï–ù–ò–Ø (—É—Ç–æ—á–Ω–µ–Ω–∏–µ): {final_analysis}")
        return final_analysis
  
    async def update_history(self, user_id: str, query: str, final_analysis: Dict[str, Any], response: list, used_objects: list = None):
        # –§–∏–ª—å—Ç—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
        filtered_response = self._filter_blocked_responses(response)
        
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å, –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        if not filtered_response:
            logger.info(f"[{user_id}] –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å. –ò—Å—Ç–æ—Ä–∏—è –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è.")
            return
            
        primary_entity = final_analysis.get("primary_entity")
        if final_analysis.get("action") == "unknown" and (not primary_entity or not primary_entity.get("name")):
            logger.debug(f"[{user_id}] –ü—Ä–æ–ø—É—Å–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–µ—Ü–µ–ª–µ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é.")
            return

        history_entry = {
            "query": query,
            "analysis": final_analysis,
            "response": filtered_response,
            # [–ò–ó–ú–ï–ù–ï–ù–ò–ï] –®–∞–≥ 2: –î–æ–±–∞–≤–ª—è–µ–º `used_objects` –≤ –∑–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏
            "used_objects": used_objects or [] 
        }

        user_context = await self.context_manager.get_context(user_id)
        history = user_context.get("history", [])
        
        updated_history = [history_entry] + history[:1]
        user_context['history'] = updated_history
        
        await self.context_manager.set_context(user_id, user_context)
        logger.info(f"[{user_id}] –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω. Query: '{query}'")
    
        
    async def get_latest_history(self, user_id: str) -> Optional[Dict[str, Any]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∞–º—É—é –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞."""
        if not self.context_manager.redis_client:
            return None
        
        user_context = await self.context_manager.get_context(user_id)
        history = user_context.get("history", [])
        
        return history[0] if history else None

  
