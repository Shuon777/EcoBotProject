import os
import json
import logging
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from langchain_gigachat import GigaChat
from langchain_core.prompts import ChatPromptTemplate
from pydantic import ValidationError
from .validator import AnalysisResponse

from .prompts_structure.prompts import UniversalPrompts

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
load_dotenv()

def load_prompt_part(file_path):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞, —Å–æ–¥–µ—Ä–∂–∞–π—â–∏–π —á–∞—Å—Ç—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è query_analyze.py
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        full_path = os.path.join(current_dir, file_path)
        
        logger.info(f"üîÑ –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å: {full_path}")
        
        with open(full_path, 'r', encoding='utf-8') as file:
            content = file.read().strip()
            logger.info(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {file_path} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return content
    except FileNotFoundError:
        logger.error(f"‚ùå –§–∞–π–ª {full_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É—é –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.")
        return ""
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {full_path}: {e}")
        return ""

class QueryAnalyzer:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            self.llm = self._init_gigachat()
            
            # –î–æ–±–∞–≤–∏–º –æ—Ç–ª–∞–¥–∫—É —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
            current_dir = os.path.dirname(os.path.abspath(__file__))
            prompts_dir = os.path.join(current_dir, 'prompts_structure')
            logger.info(f"üìÅ –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {current_dir}")
            logger.info(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è prompts_structure: {prompts_dir}")
            
            if os.path.exists(prompts_dir):
                files = os.listdir(prompts_dir)
                logger.info(f"üìã –§–∞–π–ª—ã –≤ prompts_structure: {files}")
            else:
                logger.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è prompts_structure –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {prompts_dir}")
            
            self.examples = load_prompt_part("prompts_structure/examples_for_prompt.txt")
            self.actions = load_prompt_part('prompts_structure/classifications_actions_part_of_prompt.txt')
            self.types = load_prompt_part('prompts_structure/classifications_entities_part_of_prompt.txt')
            self.flora = load_prompt_part('prompts_structure/examples_entity.txt')
            logger.info("GigaChat —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GigaChat: {str(e)}")
            raise

    def _init_gigachat(self) -> GigaChat:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GigaChat —Å API-–∫–ª—é—á–æ–º"""
        try:
            api_key = os.getenv('SBER_KEY_ENTERPRICE')
            if not api_key:
                raise ValueError("API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

            return GigaChat(
                credentials=api_key,
                model="GigaChat-2-Max",
                verify_ssl_certs=False,
                profanity_check=False,
                timeout=120,
                scope="GIGACHAT_API_CORP"
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è GigaChat –∏–Ω—Å—Ç–∞–Ω—Å–∞: {str(e)}")
            raise

    def _create_history_block(self, history: Optional[Dict[str, Any]]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –±–ª–æ–∫ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–æ–≤ API"""
        if not history:
            return ""
            
        prev_query = history.get("query")
        prev_response_list = history.get("response", [])
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        prev_response_texts = []
        for resp in prev_response_list:
            if resp.get("type") == "text":
                content = str(resp.get("content", ""))
                # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
                if not self._is_blocked_response(content):
                    prev_response_texts.append(content)
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ –±—ã–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–æ–ª—å–∫–æ –∫–∞—Ä—Ç–∞), –≤–æ–∑—å–º–µ–º caption
        if not prev_response_texts:
            for resp in prev_response_list:
                if resp.get("caption"):
                    caption = str(resp.get("caption", ""))
                    if not self._is_blocked_response(caption):
                        prev_response_texts.append(caption)

        prev_response = "\n".join(prev_response_texts).strip()

        if prev_query and prev_response:
            history_block = (
                "---\n"
                "–ü—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥:\n"
                f"- –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: \"{prev_query}\"\n"
                f"- –û—Ç–≤–µ—Ç –±–æ—Ç–∞: {prev_response}\n"
                "---\n"
            )
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç: {history_block}")
            return history_block
        return ""

    def _is_blocked_response(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—Ç–≤–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ñ—Ä–∞–∑–æ–π"""
        blocked_phrases = [
            "—è –Ω–µ –≥–æ—Ç–æ–≤ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å",
            "—è –Ω–µ –º–æ–≥—É —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å", 
            "—è –Ω–µ —É–º–µ—é —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å",
            "–Ø –Ω–µ –≥–æ—Ç–æ–≤ –ø—Ä–æ —ç—Ç–æ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å"
        ]
        text_lower = text.lower()
        return any(phrase in text_lower for phrase in blocked_phrases)

    def _extract_json_safe(self, text: str) -> Optional[str]:
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM, –æ—á–∏—â–∞—è –æ—Ç Markdown –∏
        –∏—Å–ø—Ä–∞–≤–ª—è—è –ø—Ä–æ–±–ª–µ–º—É –¥–≤–æ–π–Ω—ã—Ö —Å–∫–æ–±–æ–∫ {{...}}.
        """
        if not text:
            return None

        text = text.strip()

        # 1. –ò—â–µ–º –≥—Ä–∞–Ω–∏—Ü—ã JSON –æ–±—ä–µ–∫—Ç–∞: –æ—Ç –ø–µ—Ä–≤–æ–≥–æ '{' –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ '}'
        # –≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç—Å–µ–∫–∞–µ—Ç Markdown-–æ–±–µ—Ä—Ç–∫—É (```json ... ```) –∏ –ª–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç.
        start_idx = text.find('{')
        end_idx = text.rfind('}')

        if start_idx == -1 or end_idx == -1:
            # –ï—Å–ª–∏ —Å–∫–æ–±–æ–∫ –Ω–µ—Ç –≤–æ–æ–±—â–µ
            return None

        # –í—ã—Ä–µ–∑–∞–µ–º –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π JSON
        json_candidate = text[start_idx:end_idx + 1]

        # 2. –•–ê–ö: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–æ–π–Ω—ã—Ö —Å–∫–æ–±–æ–∫ {{...}}
        # –í–∞–ª–∏–¥–Ω—ã–π JSON-–æ–±—ä–µ–∫—Ç –æ–±—ã—á–Ω–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∫–∞–∫ { "key"...
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å—Ç—Ä–æ–≥–æ —Å {{, –∑–Ω–∞—á–∏—Ç –º–æ–¥–µ–ª—å –æ—à–∏–±–ª–∞—Å—å –∏ –¥–æ–±–∞–≤–∏–ª–∞ –ª–∏—à–Ω–∏–π —Å–ª–æ–π.
        if len(json_candidate) >= 2:
            if json_candidate.startswith("{{") and json_candidate.endswith("}}"):
                # –£–±–∏—Ä–∞–µ–º –ø–æ –æ–¥–Ω–æ–º—É —Å–∏–º–≤–æ–ª—É —Å –∫—Ä–∞–µ–≤
                json_candidate = json_candidate[1:-1]

        return json_candidate

    async def _make_llm_request(self, query: str, history_block: str) -> Optional[Dict[str, Any]]:
        """
        –î–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –æ—à–∏–±–æ–∫ (Retry Loop).
        """
        MAX_RETRIES = 2  # –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –¥–∞–µ–º —à–∞–Ω—Å –∏—Å–ø—Ä–∞–≤–∏—Ç—å—Å—è
        
        current_query_prompt = query
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        prompt_template = UniversalPrompts.analysis_prompt()
        chain = prompt_template | self.llm

        for attempt in range(MAX_RETRIES + 1):
            try:
                # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ø—ã—Ç–∫—É
                if attempt > 0:
                    logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è #{attempt} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}'")

                response = await chain.ainvoke({
                    "query": current_query_prompt, 
                    "history_block": history_block, 
                    "actions": self.actions, 
                    "examples": self.examples, 
                    "types": self.types,
                    "flora": self.flora
                })
                
                generated_text = response.content.strip()
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä (–∫–æ—Ç–æ—Ä—ã–π –º—ã –¥–æ–±–∞–≤–∏–ª–∏ –Ω–∞ –ø—Ä–æ—à–ª–æ–º —à–∞–≥–µ)
                json_text = self._extract_json_safe(generated_text)
                
                if not json_text:
                    raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ LLM")

                # –ü–∞—Ä—Å–∏–º JSON
                parsed_json = json.loads(json_text)
                
                # --- –í–ê–õ–ò–î–ê–¶–ò–Ø PYDANTIC ---
                # –≠—Ç–æ –≤—ã–±—Ä–æ—Å–∏—Ç –æ—à–∏–±–∫—É ValidationError, –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–≤–µ—Ä–Ω–∞
                validated_model = AnalysisResponse(**parsed_json)
                
                # –ï—Å–ª–∏ –≤—Å—ë –æ–∫, –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ dict (exclude_none=False –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã null –ø–æ–ª—è –æ—Å—Ç–∞–ª–∏—Å—å null)
                result_dict = validated_model.model_dump(by_alias=True)
                
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è (–ü–æ–ø—ã—Ç–∫–∞ {attempt}). Action: {result_dict.get('action')}")
                return result_dict

            except (json.JSONDecodeError, ValidationError, ValueError) as e:
                error_msg = str(e)
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt}: {error_msg}")
                
                # –ï—Å–ª–∏ —ç—Ç–æ –±—ã–ª–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —Å–¥–∞–µ–º—Å—è
                if attempt == MAX_RETRIES:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫.")
                    return None
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ø—ã—Ç–∫–∏ - —Ñ–æ—Ä–º–∏—Ä—É–µ–º "–∏—Å–ø—Ä–∞–≤–ª—è—é—â–∏–π" –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
                # –ú—ã –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∫ —Ç–µ–∫—Å—Ç—É –∑–∞–ø—Ä–æ—Å–∞, —ç–º—É–ª–∏—Ä—É—è –¥–∏–∞–ª–æ–≥
                current_query_prompt = (
                    f"{query}\n\n"
                    f"SYSTEM ERROR: –¢–≤–æ–π –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–ª –æ—à–∏–±–∫—É: {error_msg}\n"
                    f"–ò—Å–ø—Ä–∞–≤—å JSON –∏ –≤–µ—Ä–Ω–∏ –µ–≥–æ —Å–Ω–æ–≤–∞. –£–±–µ–¥–∏—Å—å, —á—Ç–æ 'subcategory' —ç—Ç–æ –º–∞—Å—Å–∏–≤, –∞ 'type' –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π."
                )
            
            except Exception as e:
                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ LLM: {e}", exc_info=True)
                return None
        return None

    async def analyze_query(self, query: str, history: Optional[Dict[str, Any]] = None) -> Optional[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø–æ–º–æ—â—å—é —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON.
        """
        logger.info(f"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
    
        # –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ - —Å –∏—Å—Ç–æ—Ä–∏–µ–π
        history_block = self._create_history_block(history)
        result = await self._make_llm_request(query, history_block)
        
        # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å –∏ –±—ã–ª–∞ –∏—Å—Ç–æ—Ä–∏—è, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏
        if result is None and history:
            logger.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è: '{query}'")
            result = await self._make_llm_request(query, "")
            
            if result is not None:
                logger.info(f"‚úÖ –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—à–µ–Ω –¥–ª—è: '{query}'")
            else:
                logger.error(f"‚ùå –û–±–∞ –∑–∞–ø—Ä–æ—Å–∞ (—Å –∏—Å—Ç–æ—Ä–∏–µ–π –∏ –±–µ–∑) –Ω–µ —É–¥–∞–ª–∏—Å—å –¥–ª—è: '{query}'")
        
        return result
        
    async def analyze_location_objects(self, geo_place: str, objects_list: list) -> dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –ª–æ–∫–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ GigaChat
        """
        try:
            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã –∏–∑ –ª–æ–∫–∞—Ü–∏–∏ "{geo_place}":
            {', '.join(objects_list)}
            
            –í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {{
                "statistics": "–∫—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
                "interesting_objects": [
                    {{
                        "name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞1",
                        "reason": "–∫–æ—Ä–æ—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)"
                    }}
                ]
            }}
            
            –í—ã–±–µ—Ä–∏ 3 —Å–∞–º—ã—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö/–∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞ –∏ –∫—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ –∏—Ö –∑–Ω–∞—á–∏–º–æ—Å—Ç—å.
            """
            
            logger.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM –¥–ª—è {geo_place}")
            response = await self.llm.ainvoke(prompt)
            logger.info(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM: {response.content}")
            
            json_text = response.content.strip()
            start_index = json_text.find('{')
            end_index = json_text.rfind('}')
            
            if start_index != -1 and end_index != -1:
                json_text = json_text[start_index:end_index+1]
                result = json.loads(json_text)
                logger.info(f"JSON —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: {result}")
                return result
            else:
                logger.error(f"JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ: {response.content}")
                raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ LLM")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ LLM: {e}", exc_info=True)
            return {
                "statistics": f"–í –ª–æ–∫–∞—Ü–∏–∏ {geo_place} –Ω–∞–π–¥–µ–Ω–æ {len(objects_list)} –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤.",
                "interesting_objects": [{"name": obj, "reason": "–∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –æ–±—ä–µ–∫—Ç"} for obj in objects_list[:3]]
            }